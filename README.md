# Orquestra√ß√£o de Dados com Kestra

## üõ†Ô∏è Introdu√ß√£o 
Este projeto pr√°tico demonstra a capacidade de orquestra√ß√£o de dados de ponta a ponta utilizando Kestra, uma poderosa plataforma open-source. O foco √© simular um cen√°rio de integra√ß√£o de dados complexa e em paralelo proveniente de m√∫ltiplas APIs externas. O pipeline desenvolvido realiza o consumo simult√¢neo desses dados, aplica transforma√ß√µes e gerencia o armazenamento em diferentes sistemas de banco de dados (PostgreSQL e MongoDB), consolidando informa√ß√µes para uso anal√≠tico ou de aplica√ß√£o.

## üìù Problema de Neg√≥cios 
O desafio de neg√≥cio abordado √© a centraliza√ß√£o e harmoniza√ß√£o de dados provenientes de fontes heterog√™neas e distribu√≠das (duas APIs distintas). Em um contexto empresarial, a tomada de decis√£o precisa de uma vis√£o unificada que n√£o pode ser alcan√ßada se os dados estiverem isolados e em formatos incompat√≠veis. O problema t√©cnico √© a necessidade de uma solu√ß√£o robusta para orquestrar o consumo paralelo dessas fontes, garantir a integridade e consist√™ncia na ingest√£o no PostgreSQL, realizar a combina√ß√£o e transforma√ß√£o necess√°rias e, finalmente, consolidar os resultados em um datastore moderno (MongoDB) para consumo r√°pido e escal√°vel.

## üéì Metodologia 
A metodologia utilizada baseia-se na implementa√ß√£o de um Pipeline de Dados Orquestrado dentro do Kestra, seguindo os princ√≠pios de um processo ETL (Extract, Transform, Load).

Extra√ß√£o Paralela (E): Duas tarefas no Kestra foram configuradas para consumir dados de APIs distintas simultaneamente, maximizando a efici√™ncia e reduzindo a lat√™ncia do pipeline.

Carga Intermedi√°ria (L): Os dados extra√≠dos foram armazenados em um banco de dados PostgreSQL, servindo como staging area e garantindo a persist√™ncia dos dados brutos/semi-brutos antes da consolida√ß√£o final.

Transforma√ß√£o e Combina√ß√£o (T): Utilizando funcionalidades do Kestra e/ou c√≥digo customizado (por exemplo, Python ou SQL), os dados do PostgreSQL foram combinados e transformados em um esquema unificado.

Carga Final (L): Os dados transformados e consolidados foram inseridos em um banco de dados MongoDB, ideal para servir a aplica√ß√µes que exigem flexibilidade de esquema ou alta performance de leitura.

Orquestra√ß√£o: Todo o fluxo foi gerenciado pelo Kestra, utilizando triggers para automa√ß√£o e monitoramento para garantir a execu√ß√£o bem-sucedida e a manipula√ß√£o de falhas.

<img width="1342" height="376" alt="image" src="https://github.com/user-attachments/assets/5d1789af-e0d3-4236-8fbe-7957e53c380c" />


## üìä Habilidades 
Orquestra√ß√£o de Workflows: Dom√≠nio da plataforma Kestra para projetar, construir e monitorar fluxos de trabalho complexos e paralelos.

Integra√ß√£o de APIs: Habilidade em consumir e manipular dados de APIs RESTful externas.

Bancos de Dados Relacionais: Conhecimento pr√°tico em PostgreSQL, incluindo ingest√£o de dados e execu√ß√£o de consultas para combina√ß√£o de datasets.

Bancos de Dados NoSQL: Experi√™ncia com MongoDB para o armazenamento final e consolida√ß√£o de dados estruturados e semi-estruturados.

Processamento Paralelo: Capacidade de configurar tarefas para execu√ß√£o simult√¢nea, otimizando o tempo de processamento do pipeline.

Data Engineering Fundamentals: Entendimento de conceitos de ETL, staging de dados e data warehousing em um contexto de modern data stack.

Pipeline as Code: Habilidade em definir fluxos de trabalho de dados de forma declarativa e automatizada.

## ü™Ñ Projeto Final 
<img width="1865" height="201" alt="image" src="https://github.com/user-attachments/assets/a4571c70-66f6-495c-8f29-6d49e1ffaaaf" />

<img width="1773" height="838" alt="image" src="https://github.com/user-attachments/assets/2bf4502f-514f-4e5f-8138-86b7f307e2c6" />













